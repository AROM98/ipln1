#!/Library/Frameworks/Python.framework/Versions/3.9/bin/python3
#!/usr/bin/python3
"""
filtro para leitura de varios ficheiro passados em linha de comando
#!/Library/Frameworks/Python.framework/Versions/3.9/bin/python3
...
"""
import sys
from getopt import getopt
from re import *
import re
from pickle import *
import spacy
import functools

n = spacy.load("en_core_web_sm")

def concat_key(ls):
    my_elems = sorted(set(ls))
    #print("lista = ",my_elems)
    return functools.reduce(lambda a,b: a + " " + b, my_elems)

def add_encounter(cap_encounters, ls):
    key_enc = concat_key(ls) # key (string) que representa as entidades
    num_enc = cap_encounters.get(key_enc, 0) + 1 # procura no dic do capito se encontra a key, se nao da 0
    cap_encounters[key_enc] = num_enc # add no dic do cap. 

def get_capitulo(god_dict, num_cap, lista_de_ents):
    init_dict = {}
    for ents in lista_de_ents:
        add_encounter(init_dict, ents)
    god_dict[num_cap] = init_dict

def pretty_print_caps(god_dict):
    
    for cap_num, cap_dict in god_dict.items():
        print('FOR CHAPTER #' + str(cap_num))
        tmp = sorted(god_dict[cap_num].items(), key=lambda x: x[1]) # ordena por nº de interaçoes
        for ents, ents_encounters in tmp:
            print('\t(' + ents + ') -> ' + str(ents_encounters))


def flatten(input_list):
    '''
    A function to flatten complex list.
    :param input_list: The list to be flatten
    :return: the flattened list.
    '''
    flat_list = []
    for i in input_list:
        if type(i) == list:
            flat_list += flatten(i)
        else:
            flat_list += [i]
    return flat_list


# vai chamar-se interact e sera a função que usa o spacy para encontrar ralaçoes entre as personagens.
def interact(frase, words):
    name_entity = [x for x in frase.ents if x.label_ in ['PERSON', 'ORG']]
    # convert all names to lowercase and remove 's in names
    name_entity = [str(x).lower().replace("'s","") for x in name_entity]
    # split names into single words ('Harry Potter' -> ['Harry', 'Potter'])
    name_entity = [x.split(' ') for x in name_entity]
    # flatten the name list
    name_entity = flatten(name_entity)
    # remove name words that are less than 3 letters to raise recognition accuracy
    name_entity = [x for x in name_entity if len(x) >= 3]
    # remove name words that are in the set of 4000 common words
    name_entity = [x for x in name_entity if x not in words]
    return name_entity


god_dict = {}
#dic2 = {('harry','voldemort'):1, ('coisa1','coisa2'):1,}
# vai dividir livro por capitulos e usar a funçao interact em cada um.
def procTexto(t, words):
    num_cap = 0
    text2 = sub(r'\f', '', txt)
    text3 = sub(r'\n\n+', '\n', text2)
    text4 = sub(r'(\n[A-Z])\n', r'\n\1', text3)
    # texto limpo
    regex = r"(CHAPTER\ \w+)\s+([A-Z\ \'\,\.\-]+)\s+(.*?|\n)(?=CHAPTER\s\w+|Text copyright)"
    #capitulos = findall(r"(CHAPTER\ \w+)\s+([A-Z\ \'\,\.\-]+)\s+(.*?|\n)(?=CHAPTER\s\w+|Text copyright)", text4)
    matches = re.finditer(regex, text4, re.DOTALL)

    for matchNum, match in enumerate(matches, start=1):
        print('.\n')
        #print('.....................................\n')
        #print(match.group(1)+'\n') # nº do capitulo
        #print(match.group(2)+'\n') # nome do capitulo
        #print(match.group(3)+'\n') # texto do capitulo
        #print('.....................................\n')

        text = n(match.group(3))
        text.vocab.vectors
        frases = list(text.sents)
        cap_ent = []
        num_cap += 1
        for j in range(0,len(frases)):
            name_entity = interact(frases[j], words)
            if name_entity: # se a lista nao for vazia adiciona
                # len(name_entity) >= 2
                cap_ent.append(name_entity)
        #print(cap_ent)
            #name_entity = sorted(set(name_entity))
            
            # -------------------------------------------------------------
        get_capitulo(god_dict, num_cap, cap_ent)
            # dentro do dic_god[capitulo] adicionar dic de dic interaçoes
    pretty_print_caps(god_dict)


ops,args = getopt(sys.argv[1:],"a:o:")
ops = dict(ops)
for ficheiro in args:
    with open(ficheiro) as f :
        txt = f.read()
    #processar o texto
    #load de palavras commum
    procTexto(txt[0], txt[1])


#diferentes opçoes
if '-a' in ops:
    pass
    #gTree(ops["-a"])
