#!/usr/bin/python3
#!/Library/Frameworks/Python.framework/Versions/3.9/bin/python3
"""
filtro para leitura de varios ficheiro passados em linha de comando
#!/Library/Frameworks/Python.framework/Versions/3.9/bin/python3
...
"""
import sys
from getopt import getopt
from re import *
import re
from pickle import *
import spacy
import functools

en = spacy.load("en_core_web_sm")
pt = spacy.load("pt_core_news_sm")

spa = en

quebraR = r'CHAPTER '
#quebraR = r'— CAPÍTULO'

ops,args = getopt(sys.argv[1:],"l:q: ")
ops = dict(ops)

if '-l' in ops:
    if(ops['-l']=='pt'):
        spa = pt
        print('Linguagem definida: ',spa.meta['lang'])
        print('A ler: ',args)
    elif(ops['-l']=='en'):
        spa = en
        print('Linguagem definida: ',spa.meta['lang'])
        print('A ler: ',args)
else:
    print("Linguagem pré definida(EN)")
    print(spa.meta['lang'])
    print('A ler: ',args)


if '-q' in ops:
    quebraR = ops['-q']



def quebra(texto):
    return re.split(quebraR ,texto)

def concat_key(ls):
    my_elems = sorted(set(ls))
    #print("lista = ",my_elems)
    return functools.reduce(lambda a,b: a + " " + b, my_elems)

def add_encounter(cap_encounters, ls):
    key_enc = concat_key(ls) # key (string) que representa as entidades
    num_enc = cap_encounters.get(key_enc, 0) + 1 # procura no dic do capito se encontra a key, se nao da 0
    cap_encounters[key_enc] = num_enc # add no dic do cap.

def get_capitulo(god_dict, num_cap, lista_de_ents):
    init_dict = {}
    for ents in lista_de_ents:
        add_encounter(init_dict, ents)
    god_dict[num_cap] = init_dict


def pretty_print_caps(god_dict):
    for cap_num, cap_dict in god_dict.items():
        print('FOR CHAPTER #' + str(cap_num))
        tmp = sorted(god_dict[cap_num].items(), key=lambda x: x[1]) # ordena por nº de interaçoes
        for ents, ents_encounters in tmp:
            print('\t(' + ents + ') -> ' + str(ents_encounters))


def flatten(input_list):
    '''
    A function to flatten complex list.
    :param input_list: The list to be flatten
    :return: the flattened list.
    '''
    flat_list = []
    for i in input_list:
        if type(i) == list:
            flat_list += flatten(i)
        else:
            flat_list += [i]
    return flat_list


# vai chamar-se interact e sera a função que usa o spacy para encontrar ralaçoes entre as personagens.
def interact(frase):
    #print('frase: ',frase)
    name_entity = [x for x in frase.ents if x.label_ in ['PER','PERSON']]
    #print('entidades: ',name_entity)
    #print('b:',name_entity)

    #print('a:',name_entity)
    # convert all names to lowercase and remove 's in names
    name_entity = [str(x).replace("'s","") for x in name_entity]

    name_entity = [str(x) for x in name_entity if x[0].isupper()]
    #print(name_entity)
    # split names into single words ('Harry Potter' -> ['Harry', 'Potter'])
    name_entity = [x.replace(' ','_') for x in name_entity]
    # flatten the name list
    name_entity = flatten(name_entity)
    # remove name words that are less than 3 letters to raise recognition accuracy
    name_entity = [x for x in name_entity if len(x) >= 3]
    return name_entity

god_dict = {}
# vai dividir livro por capitulos e usar a funçao interact em cada um.
def procTexto(t):
    num_cap = 0
    #text2 = sub(r'\f', '', txt)
    #text3 = sub(r'\n\n+', '\n', text2)
    #text4 = sub(r'(\n[A-Z])\n', r'\n\1', text3)
    # texto limpo
    #regex = r"(CHAPTER\ \w+)\s+([A-Z\ \'\,\.\-]+)\s+(.*?|\n)(?=CHAPTER\s\w+|Text copyright)"
    #capitulos = findall(r"(CHAPTER\ \w+)\s+([A-Z\ \'\,\.\-]+)\s+(.*?|\n)(?=CHAPTER\s\w+|Text copyright)", text4)

    #matches = re.finditer(regex, text4, re.DOTALL)
    capitulos = quebra(t)

    #for matchNum, match in enumerate(matches, start=1):
    for cap in capitulos:
        print('.\n')
        #print('.....................................\n')
        #print(match.group(1)+'\n') # nº do capitulo
        #print(cap)
        #print(match.group(2)+'\n') # nome do capitulo
        #print(match.group(3)+'\n') # texto do capitulo
        #print('.....................................\n')

        #text = pt(match.group(3))
        text = spa(cap)
        text.vocab.vectors
        frases = list(text.sents)
        cap_ent = []
        num_cap += 1
        for j in range(0,len(frases)):

            name_entity = interact(frases[j])
            #print('name_entity: ',name_entity)
            if name_entity: # se a lista nao for vazia adiciona
                # len(name_entity) >= 2
                cap_ent.append(name_entity)
        #print(cap_ent)
            #name_entity = sorted(set(name_entity))
            # -------------------------------------------------------------
        get_capitulo(god_dict, num_cap, cap_ent)
            # dentro do dic_god[capitulo] adicionar dic de dic interaçoes
    pretty_print_caps(god_dict)


for ficheiro in args:
    with open(ficheiro) as f :
        txt = f.read()
    #processar o texto
    procTexto(txt)


#diferentes opçoes
if '-a' in ops:
    pass
    #gTree(ops["-a"])
